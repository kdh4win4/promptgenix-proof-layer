<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>SBIR Project Summary â€” PromptGenix Proof Layer</title>
  <style>
    body { margin:0; padding:24px; background:#0b0f14; color:#e8eef6;
      font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial; }
    .wrap { max-width:900px; margin:0 auto; }
    h1 { margin:0 0 8px; font-size:22px; }
    h2 { margin:24px 0 8px; font-size:16px; }
    p { line-height:1.6; font-size:14px; color:#d7e3f1; }
    .card { background:#0f1621; border:1px solid #223042; border-radius:12px; padding:18px; }
    .muted { color:#9fb0c3; font-size:12px; }
  </style>
</head>
<body>
  <div class="wrap">
    <h1>Project Summary</h1>
    <p class="muted">PromptGenix Proof Layer</p>

    <div class="card">
      <h2>Overview</h2>
      <p>
        Artificial intelligence (AI) is increasingly used to generate scientific analyses,
        regulatory summaries, and decision-support outputs in high-stakes environments.
        However, AI-generated content is inherently mutable and often lacks verifiable
        records of provenance, making independent auditing and reproducibility difficult.
      </p>

      <h2>Technical Innovation</h2>
      <p>
        This project proposes a lightweight proof layer that enables cryptographic
        verification of AI-generated outputs and their provenance without storing
        sensitive content. The system hashes AI prompts and outputs, associates them
        with structured metadata, and stores the resulting proof records permanently
        on the Arweave decentralized storage network.
      </p>

      <h2>Objectives</h2>
      <p>
        The Phase I objective is to design, implement, and validate a proof-of-concept
        system that enables immutable timestamping and independent verification of
        AI-generated results using Arweave transaction identifiers.
      </p>

      <h2>Expected Outcomes</h2>
      <p>
        Expected outcomes include a validated proof-generation pipeline, independent
        verification tools, and demonstration of feasibility for deployment in
        government, research, and regulated environments.
      </p>

      <h2>Broader Impact</h2>
      <p>
        This project addresses a critical gap in AI trust infrastructure by enabling
        transparent, auditable, and reproducible AI-assisted decision-making.
        The results will support future Phase II development and broader adoption
        across public-sector and enterprise systems.
      </p>
    </div>
  </div>
</body>
</html>
